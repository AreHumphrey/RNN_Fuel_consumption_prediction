import numpy as np
import tensorflow as tf
import joblib

model = tf.keras.models.load_model("fuel_lstm_model.keras")

scaler_X = joblib.load("scaler_X.pkl")
scaler_y = joblib.load("scaler_y.pkl")

test_cases = [
    # –ì–æ—Ä–æ–¥—Å–∫–∏–µ —É—Å–ª–æ–≤–∏—è
    ("–ì–æ—Ä–æ–¥—Å–∫–∞—è –µ–∑–¥–∞ (–±–µ–Ω–∑–∏–Ω, –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ)", [50, 2000, 18, 1400, 0.30, 85, 0, 1, 0, 2.5, 0]),
    ("–ì–æ—Ä–æ–¥—Å–∫–∞—è –µ–∑–¥–∞ (–¥–∏–∑–µ–ª—å, –Ω–∏–∑–∫–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ)", [50, 2200, 15, 1600, 0.31, 80, 0, 2, 1, 2.0, 0]),

    # –¢—Ä–∞—Å—Å–∞ –∏ –≤—ã—Å–æ–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å
    ("–®–æ—Å—Å–µ (–¥–∏–∑–µ–ª—å, –Ω–∏–∑–∫–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ)", [120, 3500, 25, 1600, 0.31, 90, 0, 2, 1, 2.0, 0]),
    ("–®–æ—Å—Å–µ (–±–µ–Ω–∑–∏–Ω, –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ)", [120, 3200, 22, 1400, 0.30, 95, 0, 1, 0, 2.5, 0]),
    ("–í—ã—Å–æ–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å (–≥–∏–±—Ä–∏–¥, –º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç)", [150, 5000, 30, 1700, 0.32, 95, 0, 3, 2, 2.8, 2]),

    # –•–æ–ª–æ–¥–Ω—ã–π —Å—Ç–∞—Ä—Ç –∏ –ø–æ–≥–æ–¥–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
    ("–•–æ–ª–æ–¥–Ω—ã–π —Å—Ç–∞—Ä—Ç (-5¬∞C, 80 –∫–º/—á, 2 –ø–∞—Å—Å–∞–∂–∏—Ä–∞)", [80, 2500, -5, 1600, 0.33, 50, 0, 2, 0, 2.5, 0]),
    ("–ñ–∞—Ä–∞ (35¬∞C, 90 –∫–º/—á, –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä –≤–∫–ª—é—á–µ–Ω)", [90, 3000, 35, 1500, 0.32, 85, 0, 2, 0, 2.5, 0]),

    # –î–æ—Ä–æ–∂–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
    ("–ì–æ—Ä–Ω–∞—è –¥–æ—Ä–æ–≥–∞ (–±–µ–Ω–∑–∏–Ω, –≥—Ä—É–Ω—Ç–æ–≤–∫–∞)", [100, 4000, 15, 1800, 0.34, 85, 10, 2, 0, 2.3, 1]),
    ("–ì–æ—Ä–Ω–∞—è –¥–æ—Ä–æ–≥–∞ (–≥–∏–±—Ä–∏–¥, –º–æ–∫—Ä—ã–π –∞—Å—Ñ–∞–ª—å—Ç)", [100, 3800, 15, 1700, 0.32, 90, 10, 2, 2, 2.5, 2]),
    ("–°–ø—É—Å–∫ (90 –∫–º/—á, —Å–Ω–∏–∂–µ–Ω–∏–µ —É–∫–ª–æ–Ω–∞ -5¬∞)", [90, 3000, 20, 1500, 0.30, 85, -5, 2, 0, 2.5, 0]),

    # –†–∞–∑–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–∞—à–∏–Ω—ã
    ("–ü–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–Ω—ã–π –∞–≤—Ç–æ (110 –∫–º/—á, 5 –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤, —Ç—è–∂–µ–ª–∞—è –º–∞—à–∏–Ω–∞)", [110, 3800, 22, 2000, 0.36, 90, 0, 5, 0, 2.5, 0]),
    ("–õ–µ–≥–∫–∏–π –∞–≤—Ç–æ (110 –∫–º/—á, 1 –ø–∞—Å—Å–∞–∂–∏—Ä, –º–∞–ª–µ–Ω—å–∫–∞—è –º–∞—à–∏–Ω–∞)", [110, 3600, 22, 1200, 0.28, 90, 0, 1, 0, 2.5, 0]),

    # –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
    ("–î–æ—Ä–æ–≥–∞ —Å —Å–∏–ª—å–Ω—ã–º —É–∫–ª–æ–Ω–æ–º (–ø–æ–¥—ä–µ–º 15¬∞)", [100, 4200, 18, 1800, 0.34, 85, 15, 2, 0, 2.5, 0]),
    ("–î–æ—Ä–æ–≥–∞ —Å —Å–∏–ª—å–Ω—ã–º —É–∫–ª–æ–Ω–æ–º (—Å–ø—É—Å–∫ -15¬∞)", [100, 3000, 18, 1800, 0.34, 85, -15, 2, 0, 2.5, 0]),
]

results = []
for description, test_data in test_cases:
    test_data = np.array([test_data])
    test_data_scaled = scaler_X.transform(test_data).reshape(1, test_data.shape[1], 1)
    predicted_fuel = model.predict(test_data_scaled)
    predicted_fuel = scaler_y.inverse_transform(predicted_fuel)
    results.append(f"{description}: üêó {predicted_fuel[0][0]:.2f} –ª/100 –∫–º")
    print(results[-1])

with open("predictions_lstm.txt", "w", encoding="utf-8") as file:
    file.write("\n".join(results))

print("\n–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ —Ñ–∞–π–ª–∏–∫ predictions_lstm.txt üêª")
